{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Sorting Demo (vLLM): \"Can 5 Agents Sort Themselves?\"\n",
    "\n",
    "This notebook is designed for a lecture demo on sorting algorithms.  \n",
    "Five LLM personas (with names already in alphabetical order) start in a shuffled line and **talk to each other** while performing adjacent comparisons.\n",
    "\n",
    "## Learning goals\n",
    "1. Visualize a sorting process step-by-step.\n",
    "2. Show how local communication (neighbor-to-neighbor) can still produce a globally sorted order.\n",
    "3. Count algorithmic cost and compare to theoretical optima.\n",
    "4. Use `vllm` to generate live dialogue so students can *see and hear* what each comparison is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Environment Setup\n",
    "\n",
    "> This demo uses one base model through `vllm` and assigns five different personas.\n",
    "> It works well with an instruction-tuned model (for example Llama-3-Instruct style checkpoints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, install dependencies in your environment:\n",
    "# !pip install vllm matplotlib pandas ipywidgets\n",
    "\n",
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Configure your model path ----\n",
    "# Examples:\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_name = \"/models/Meta-Llama-3-8B-Instruct\"\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    max_tokens=120,\n",
    ")\n",
    "\n",
    "# Set True for a fast classroom dry-run without loading a model.\n",
    "USE_MOCK_DIALOGUE = False\n",
    "\n",
    "# Initialize once (can take time, depending on your hardware)\n",
    "llm = None if USE_MOCK_DIALOGUE else LLM(model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Preview Mode (before full vLLM run)\n",
    "\n",
    "If you want to preview the demo instantly in class before loading a model:\n",
    "1. Set `USE_MOCK_DIALOGUE = True`.\n",
    "2. Run all cells.\n",
    "\n",
    "You will still get the full sorting animation and step-count analysis, but dialogue is deterministic and fast.\n",
    "Then switch back to `False` for live vLLM-generated agent conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Define the Five LLM Personas\n",
    "\n",
    "The names are intentionally alphabetical:\n",
    "\n",
    "- **Aster**\n",
    "- **Beryl**\n",
    "- **Cygnus**\n",
    "- **Dahlia**\n",
    "- **Ember**\n",
    "\n",
    "We then shuffle their starting order to create a sorting challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personas = [\"Aster\", \"Beryl\", \"Cygnus\", \"Dahlia\", \"Ember\"]\n",
    "\n",
    "random.seed(140)\n",
    "start_order = personas.copy()\n",
    "random.shuffle(start_order)\n",
    "\n",
    "start_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StepRecord:\n",
    "    step: int\n",
    "    left_index: int\n",
    "    right_index: int\n",
    "    left_name: str\n",
    "    right_name: str\n",
    "    should_swap: bool\n",
    "    order_after: List[str]\n",
    "    left_message: str\n",
    "    right_message: str\n",
    "\n",
    "\n",
    "def inversion_count(arr: List[str]) -> int:\n",
    "    \"\"\"Number of adjacent swaps required by any adjacent-swap sorting process.\"\"\"\n",
    "    inv = 0\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(i + 1, len(arr)):\n",
    "            if arr[i] > arr[j]:\n",
    "                inv += 1\n",
    "    return inv\n",
    "\n",
    "\n",
    "def info_theory_lower_bound_comparisons(n: int) -> int:\n",
    "    \"\"\"Lower bound on comparisons for any comparison sort: ceil(log2(n!)).\"\"\"\n",
    "    return math.ceil(math.log2(math.factorial(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) LLM Communication Function\n",
    "\n",
    "For each adjacent pair, both agents speak:\n",
    "\n",
    "- Left agent explains whether it should stay/swap.\n",
    "- Right agent responds.\n",
    "\n",
    "To keep the algorithm correct and stable for teaching, the **actual swap decision is made by exact lexical comparison** (`left_name > right_name`).\n",
    "The model-generated text provides the social/visual explanation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_agent(agent_name: str, other_name: str, side: str, should_swap: bool) -> str:\n",
    "    decision_word = \"SWAP\" if should_swap else \"KEEP\"\n",
    "\n",
    "    if USE_MOCK_DIALOGUE:\n",
    "        verb = \"move left\" if should_swap else \"hold position\"\n",
    "        return (\n",
    "            f\"I'm {agent_name} on the {side}; compared with {other_name}, I should {verb}. \"\n",
    "            f\"Decision={decision_word}\"\n",
    "        )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are {agent_name}, an LLM persona standing next to {other_name} in a sorting line.\n",
    "Your side: {side}.\n",
    "Ground-truth decision from referee: {decision_word}.\n",
    "\n",
    "In 1-2 short sentences:\n",
    "1) Explain your local comparison using alphabetical order.\n",
    "2) End with exactly: Decision={decision_word}\n",
    "Tone: lively for a classroom demo.\n",
    "\"\"\".strip()\n",
    "\n",
    "    outputs = llm.generate([prompt], sampling_params)\n",
    "    return outputs[0].outputs[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_state(order: List[str], title: str, highlight: tuple = None):\n",
    "    \"\"\"\n",
    "    Draw a horizontal lineup of personas.\n",
    "    highlight: optional (i, j, swapped_bool)\n",
    "    \"\"\"\n",
    "    n = len(order)\n",
    "    fig, ax = plt.subplots(figsize=(12, 2.8))\n",
    "    ax.set_xlim(0, n)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    for idx, name in enumerate(order):\n",
    "        x = idx + 0.05\n",
    "        w = 0.9\n",
    "        h = 0.55\n",
    "        color = \"#7ec8e3\"\n",
    "\n",
    "        if highlight and idx in (highlight[0], highlight[1]):\n",
    "            color = \"#ffd166\" if highlight[2] else \"#caffbf\"\n",
    "\n",
    "        rect = patches.FancyBboxPatch(\n",
    "            (x, 0.2), w, h,\n",
    "            boxstyle=\"round,pad=0.02,rounding_size=0.04\",\n",
    "            linewidth=2,\n",
    "            edgecolor=\"#1f2937\",\n",
    "            facecolor=color,\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(idx + 0.5, 0.48, name, ha=\"center\", va=\"center\", fontsize=12, weight=\"bold\")\n",
    "\n",
    "    if highlight:\n",
    "        i, j, swapped = highlight\n",
    "        action = \"SWAP\" if swapped else \"KEEP\"\n",
    "        ax.annotate(\n",
    "            action,\n",
    "            xy=((i + j + 1)/2, 0.85),\n",
    "            ha=\"center\",\n",
    "            fontsize=12,\n",
    "            weight=\"bold\",\n",
    "            color=\"#111827\",\n",
    "        )\n",
    "\n",
    "    plt.title(title, fontsize=14, weight=\"bold\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Run the \"Self-Sorting\" Conversation (Odd-Even Neighbor Passes)\n",
    "\n",
    "We use an adjacent-comparison strategy (bubble-style neighbor exchanges):\n",
    "\n",
    "- Pass 1: compare (0,1), (1,2), (2,3), (3,4)\n",
    "- Repeat passes until sorted.\n",
    "\n",
    "This is perfect for a communication demo because each action is local and visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_demo(initial_order: List[str]) -> Dict[str, Any]:\n",
    "    order = initial_order.copy()\n",
    "    history: List[StepRecord] = []\n",
    "    step = 0\n",
    "\n",
    "    draw_state(order, title=\"Initial lineup (shuffled)\")\n",
    "\n",
    "    n = len(order)\n",
    "    for pass_num in range(1, n):  # bubble-sort style upper bound\n",
    "        swapped_this_pass = False\n",
    "        display(Markdown(f\"### Pass {pass_num}\"))\n",
    "\n",
    "        for i in range(0, n - 1):\n",
    "            j = i + 1\n",
    "            left, right = order[i], order[j]\n",
    "            should_swap = left > right\n",
    "\n",
    "            left_msg = ask_agent(left, right, \"LEFT\", should_swap)\n",
    "            right_msg = ask_agent(right, left, \"RIGHT\", should_swap)\n",
    "\n",
    "            if should_swap:\n",
    "                order[i], order[j] = order[j], order[i]\n",
    "                swapped_this_pass = True\n",
    "\n",
    "            step += 1\n",
    "            rec = StepRecord(\n",
    "                step=step,\n",
    "                left_index=i,\n",
    "                right_index=j,\n",
    "                left_name=left,\n",
    "                right_name=right,\n",
    "                should_swap=should_swap,\n",
    "                order_after=order.copy(),\n",
    "                left_message=left_msg,\n",
    "                right_message=right_msg,\n",
    "            )\n",
    "            history.append(rec)\n",
    "\n",
    "            draw_state(\n",
    "                order,\n",
    "                title=f\"Step {step}: compare {left} vs {right}\",\n",
    "                highlight=(i, j, should_swap),\n",
    "            )\n",
    "\n",
    "            display(Markdown(\"**{} says:** {}\\n\\n**{} says:** {}\".format(left, left_msg, right, right_msg)))\n",
    "\n",
    "        if not swapped_this_pass:\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"final_order\": order,\n",
    "        \"steps\": step,\n",
    "        \"history\": history,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_demo(start_order)\n",
    "results[\"final_order\"], results[\"steps\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Metrics: Steps vs Optimal\n",
    "\n",
    "We compute:\n",
    "\n",
    "1. **Our observed comparisons** = number of neighbor checks performed.\n",
    "2. **Observed swaps** = number of inversions resolved during run.\n",
    "3. **Optimal adjacent swaps** = inversion count of the initial permutation.\n",
    "4. **Information-theoretic lower bound on comparisons** = `ceil(log2(5!)) = 7`.\n",
    "\n",
    "For `n=5`, bubble-like neighbor strategies typically use more than 7 comparisons, which is a great teaching point: **local communication clarity vs comparison efficiency**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = start_order\n",
    "final_order = results[\"final_order\"]\n",
    "history = results[\"history\"]\n",
    "\n",
    "observed_comparisons = len(history)\n",
    "observed_swaps = sum(1 for h in history if h.should_swap)\n",
    "optimal_adj_swaps = inversion_count(initial)\n",
    "lb_comparisons = info_theory_lower_bound_comparisons(len(initial))\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"Metric\": \"Initial order\", \"Value\": \" -> \".join(initial)},\n",
    "    {\"Metric\": \"Final order\", \"Value\": \" -> \".join(final_order)},\n",
    "    {\"Metric\": \"Observed comparisons (this demo)\", \"Value\": observed_comparisons},\n",
    "    {\"Metric\": \"Observed swaps (this demo)\", \"Value\": observed_swaps},\n",
    "    {\"Metric\": \"Optimal adjacent swaps (= inversions)\", \"Value\": optimal_adj_swaps},\n",
    "    {\"Metric\": \"Lower bound comparisons ceil(log2(5!))\", \"Value\": lb_comparisons},\n",
    "])\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed step table for classroom walkthrough\n",
    "rows = []\n",
    "for h in history:\n",
    "    rows.append({\n",
    "        \"Step\": h.step,\n",
    "        \"Pair\": f\"({h.left_index},{h.right_index})\",\n",
    "        \"Compared\": f\"{h.left_name} vs {h.right_name}\",\n",
    "        \"Action\": \"SWAP\" if h.should_swap else \"KEEP\",\n",
    "        \"Order after step\": \" -> \".join(h.order_after),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) How to Explain This in Class\n",
    "\n",
    "### Why this is \"LLMs sorting themselves\"\n",
    "- Each comparison is narrated by both neighboring agents.\n",
    "- The global ordering emerges from local pairwise interactions.\n",
    "- Students can track **state transitions** visually after each step.\n",
    "\n",
    "### Algorithmic angle\n",
    "- With adjacent swaps, the exact minimum number of swaps equals the inversion count.\n",
    "- But minimum number of comparisons for arbitrary comparison sorting is bounded by `log2(n!)`.\n",
    "- This demo intentionally prioritizes interpretability and communication over optimal comparison count.\n",
    "\n",
    "### Extensions\n",
    "1. Replace bubble-style passes with insertion-sort dialogue.\n",
    "2. Add a \"moderator\" agent that asks only one question per pair.\n",
    "3. Let agents vote on uncertainty before referee enforces exact order.\n",
    "4. Run multiple random initial orders and plot average steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}